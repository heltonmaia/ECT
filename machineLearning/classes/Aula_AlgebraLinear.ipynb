{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula_AlgebraLinear.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UPOP28BvubVJ",
        "F8vl36okxled"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiEOYgszwvLD"
      },
      "source": [
        "# Estudaremos nessa aula:\n",
        "- Conceitos básicos e operações com o numpy\n",
        "- Algebra Linear\n",
        "\n",
        "Material de suporte:\n",
        "\n",
        "1.   [Book: Python for Data Analysis ](https://www.cin.ufpe.br/~embat/Python%20for%20Data%20Analysis.pdf) \n",
        "2.   [Book: Dive into Deep Learning](http://d2l.ai/chapter_preliminaries/ndarray.html)\n",
        "3.   [Video: Algebra Linear](https://youtu.be/dtX8iQGQQkI)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXBUCUakG2jW"
      },
      "source": [
        "#importando bibliotecas para uso em todo o code\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPOP28BvubVJ"
      },
      "source": [
        "# Utilizando o numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_65xna_ucsw"
      },
      "source": [
        "#criando arrays\n",
        "data1 = [1,2,3,4,5.5]\n",
        "data2 = np.array([1,2,3,4,5.5]) #a partir de uma lista\n",
        "data3 = np.array(data1)\n",
        "\n",
        "#exibindo tamanho e shape\n",
        "print(type(data1), np.size(data1))\n",
        "print(type(data2), np.size(data2), data2.shape)\n",
        "\n",
        "#criando arrays de zeros\n",
        "data_zeros = np.zeros((2,3))\n",
        "data_cont = np.arange(5)\n",
        "\n",
        "#criando array, especificando o tipo\n",
        "data_float = np.array([1,2,3], dtype=np.int32)\n",
        "print(data2.dtype)\n",
        "print(data_float.dtype)\n",
        "\n",
        "#criando array com o linspace\n",
        "array_lins1 = np.linspace(5,25,5)\n",
        "print(array_lins1)\n",
        "\n",
        "#cirando array e mudando o shape\n",
        "data4 = np.arange(12)\n",
        "print(data4)\n",
        "data4 = data4.reshape(3,4)\n",
        "print(data4)\n",
        "\n",
        "#ciando uma array, utilizando uma distribuicao de probabilidades normal, mean=0, std=1\n",
        "dist = np.random.normal(0, 1, size=(3, 4))\n",
        "print(dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8vl36okxled"
      },
      "source": [
        "# Operações básicas com arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbb9p1dvxrFy"
      },
      "source": [
        "#criando array\n",
        "#numpy permite operacoes de batch em vez de loops, like matlab\n",
        "arr = np.array([[1., 2., 3.], [4., 5., 6.]])\n",
        "print(arr)\n",
        "\n",
        "#element-wise operations entre arrays de mesmo tamanho\n",
        "print(arr * arr)\n",
        "print(arr - arr)\n",
        "print(1 / arr)\n",
        "print(arr ** 3)\n",
        "print(arr > arr/2)\n",
        "\n",
        "#sum, prod, mean, std, var, min, max, argmin, argmax\n",
        "arr_ope = np.array([1,2,3,4,5])\n",
        "print(\"---------------\")\n",
        "print(arr_ope)\n",
        "print(np.sum(arr_ope))\n",
        "print(np.prod(arr_ope))\n",
        "print(np.mean(arr_ope))\n",
        "print(np.std(arr_ope))\n",
        "print(np.var(arr_ope))\n",
        "print(np.min(arr_ope))\n",
        "print(np.max(arr_ope))\n",
        "print(np.argmin(arr_ope)) #retorna o indice do valor min\n",
        "print(np.argmax(arr_ope)) #retorna o indice do valor max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCP2gc5k0hB2"
      },
      "source": [
        "***Data Manipulation***\n",
        "\n",
        "Dados dois vetores $u$ e $v$ de mesma dimensão, e uma operação binária $f$, isto é, uma função de mapeamento $f:ℝ,ℝ \\to ℝ$, podemos produzir um vetor resultande $c=F(u,v)$. \n",
        "Considere que $c_i \\gets (u_i,v_i)$ para todo $i$, onde $c_i$, $u_i$ e $v_i$ são $i^{th}$ elementos dos vetores $c$, $u$, e $v$.\n",
        "Desta forma, pode-se produzir valores vetoriais $F:ℝ^d, ℝ^d \\to ℝ^d$ utilizando uma função escalar a partir de operações vetoriais elementares, do inglês, *elementwise operations*.\n",
        "É importante resaltar que os operadores aritméticos padrão ($+,-,*,/,**$), realizam operações elementares nos arrays, veja o exemplo abaixo.  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3Lidumc0f80"
      },
      "source": [
        "#outras operacoes\n",
        "x = np.array([1, 2, 4, 8])\n",
        "y = np.array([2, 2, 2, 2])\n",
        "print(x + y, x - y, x * y, x / y, x ** y)  # O operador ** é exponencial\n",
        "\n",
        "#np.where: mostra os indices dos elementos que obedecem a uma certa condição\n",
        "print(\"---------------\")\n",
        "a = np.array([1, 2, 3, 4, 5, 6]) \n",
        "print(a)   \n",
        "print ('Indices de elementos < 4') \n",
        "b = np.where(a < 4) \n",
        "print(b) \n",
        "print(\"Elementos que sao < 4\") \n",
        "print(a[b]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTcXEgg_0mij"
      },
      "source": [
        "#Trabalhando com indices\n",
        "arr = np.arange(10)\n",
        "print(arr)\n",
        "print(arr[1:3])\n",
        "print(arr[-1])\n",
        "\n",
        "arr2 = arr[1:5]\n",
        "arr2[0] = 123\n",
        "\n",
        "#veja a referencia\n",
        "print('arr: ',arr)\n",
        "print('arr2: ',arr2)\n",
        "\n",
        "#arrays com 2 dimensoes\n",
        "arr2d = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "arr2d[0][1]=22\n",
        "print('2D: ')\n",
        "print(arr2d)\n",
        "\n",
        "#arrays com 3 dimensoes\n",
        "arr3d = np.array([[[1,2,3],[4,5,6],[7,8,9]], [[1,2,3],[4,5,6],[7,8,9]]])\n",
        "print('3D: ')\n",
        "print(arr3d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6on2-K8dm-vg"
      },
      "source": [
        "# verificando dimensao e tamanho\n",
        "print(arr3d.shape)\n",
        "print(np.size(arr3d))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2PUDOiMIO9s"
      },
      "source": [
        "**(Exercício)** Mover para lista de exercicios\n",
        "\n",
        "Muitas vezes precisamos convertes tipos de dados, por exemplo, um vetor de inteiros deveria ser do tipo float. Pesquisem como fazer isso em Python utilizando a bibliotexa numpy, mostrando exemplos de funcionamento. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbBI-wuHGqNQ"
      },
      "source": [
        "#convertendo tipos\n",
        "a = np.array([1.5,2.4,3])\n",
        "print('Original',type(a))\n",
        "print(a)\n",
        "\n",
        "a = a.astype(int)\n",
        "print('Convertido para int')\n",
        "print(a)\n",
        "\n",
        "a = a.astype(float)\n",
        "print('Convertido para float')\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvykJSR-06PO"
      },
      "source": [
        "# Álgebra Linear\n",
        "- Conteúdo baseado no book: http://d2l.ai/chapter_preliminaries/linear-algebra.html#\n",
        "- Extra video: [How to Become a Data Scientist](https://youtu.be/jMvhFNGGT_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bCteZVdQgq-"
      },
      "source": [
        "## Vetores\n",
        "\n",
        "Para o *machine learning*, você pode pensar em um vetor como sendo uma simples lista de escalares:\n",
        "\n",
        "Exemplo: $\\mathbf{x} = [1,2,3,4,5]$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0X6Pa0Zu7Wg"
      },
      "source": [
        "#vet = np.arange(1,6,1)\n",
        "x = np.array([1,2,3,4,5])\n",
        "print('Valores:', x)\n",
        "print('Shape: ',x.shape)\n",
        "print('Tamanho:', len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usYkUDEDRsmY"
      },
      "source": [
        "Na matemática, a disposição em colunas é o padrão, assim, o vetor $\\mathbf{x}$ pode ser escrito da sequinte forma:\n",
        "\n",
        "$$\n",
        "\\mathbf{x} =\\begin{bmatrix}x_{1}  \\\\x_{2}  \\\\ \\vdots  \\\\x_{n}\\end{bmatrix},\n",
        "$$\n",
        "\n",
        "onde $x_1, \\ldots, x_n$ são elementos do vetor \"`ndarray`\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yisVbzrTT7GD"
      },
      "source": [
        "## Matrizes\n",
        "\n",
        "Na notação matemática, utilizamos $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$\n",
        "para expressar que a matriz $\\mathbf{A}$ consiste em $m$ linhas e $n$ colunas de valores escalares reais.\n",
        "Visualmente, pode-se ilustrar qualquer matriz $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ como uma tabela, onde cada elemento $a_{ij}$ pertence a $i^{\\mathrm{th}}$ linha e $j^{\\mathrm{th}}$ coluna, descrito no exemplo abaixo:\n",
        "\n",
        "$$\n",
        "\\mathbf{A}=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Para qualquer $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, a dimensão de $\\mathbf{A}$ é ($m$, $n$) ou $m \\times n$. Quando a matriz tem o mesmo numero de linhas e colunas, chamamos de matriz quadrada, do inglês, *square matrix*.\n",
        "\n",
        "Pode-se criar uma matriz $m \\times n$ matrix com o numpy, especificando sua dimensão $m$ and $n$ como no exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1D33zkMaO9u"
      },
      "source": [
        "A = np.arange(20).reshape(5, 4)\n",
        "print(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiRSJAFmhj4g"
      },
      "source": [
        "Pode-se facilmente acessar qualquer elemento escalar $a_{ij}$ da matriz $\\mathbf{A}$. Para isso, é preciso apenas especificar o índice para acesso da linha ($i$) e coluna ($j$), respectivamente, por exemplo $[\\mathbf{A}]_{ij}$.\n",
        "Algumas vezes é preciso trabalhar a matriz transposta, ou seja, trocar as linhas por colunas desta matriz. Formalmente, temos a matriz $\\mathbf{A}$ transposta, definida como $\\mathbf{A}^\\top$.\n",
        "Considerando $\\mathbf{B} = \\mathbf{A}^\\top$, temos $b_{ij} = a_{ji}$ para\n",
        "qualquer $i$ e $j$. \n",
        "\n",
        "Por exemplo:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\mathbf{A}^\\top =\n",
        "  \\begin{bmatrix}\n",
        "      a_{11} & a_{21} & \\dots  & a_{m1} \\\\\n",
        "      a_{12} & a_{22} & \\dots  & a_{m2} \\\\\n",
        "      \\vdots & \\vdots & \\ddots  & \\vdots \\\\\n",
        "      a_{1n} & a_{2n} & \\dots  & a_{mn}\n",
        "  \\end{bmatrix}.\n",
        "\\end{equation}\n",
        "\n",
        "Em um Python code, podemos obter uma matriz transposta via atributo `T`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRLV0tvunA3_"
      },
      "source": [
        "#matriz transposta\n",
        "print(A.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WQ7VNT13aqR"
      },
      "source": [
        "Existe um tipo especial de matriz quadrada na qual chamamos de matriz simétrica, isto é, a original é igual a sua transposta: \n",
        "$\\mathbf{A} = \\mathbf{A}^\\top$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNADrxsD3ZkM"
      },
      "source": [
        "B = np.array([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
        "print('Original: \\n', B)\n",
        "print('Transposta: \\n',B.T)\n",
        "print('---------------')\n",
        "#testando valores lógicos\n",
        "print('Teste Lógico: \\n', B==B.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUzD2peSQo9y"
      },
      "source": [
        "## Tensores (*Tensors*)\n",
        "\n",
        "Assim como os vetores generalizam os escalares, as matrizes generalizam os vetores, os tensores as matrizes, e assim por diante. Desta forma, podemos criar estruturas ainda maiores. Utilizando `ndarray`s pode-se definir o número de axes desejado, por exemplo, tensores de primeira ordem (vetores), de segunda ordem (matrizez), e qualquer outra ordem superior.\n",
        "\n",
        "Tensores são descritos com *capital letters* assim como as matrizes\n",
        "(e.g., $\\mathsf{X}$, $\\mathsf{Y}$, and $\\mathsf{Z}$), tendo seu mecanismo de indexação também similar (e.g., $x_{ijk}$ and $[\\mathsf{X}]_{1, 2i-1, 3}$).\n",
        "\n",
        "Tensores são especialmente importantes quando se deseja trabalhar com imagens e vídeos (sequeência de frames). Uma imagem colorida possui altura, largura e normalmente 3 canais de cores, *red* (R), *green* (G) e *blue* (B).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfpkFb7HfcVR"
      },
      "source": [
        "#exemplo de tensor\n",
        "X = np.arange(24).reshape(2, 3, 4) \n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy2xdd77mcM7"
      },
      "source": [
        "Escalares, vetores, matrizes e tensores possuem uma relação direta com o número de *axes*, com isso, diversas propriedades.\n",
        "\n",
        "Primeiramente, note que as oeprações *elementwise* nãão mudam a dimensão do tensor resultando, assim como ocorre nas matrizes. O exemplo abaixo realixa a soma de dois tensores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFfhtStAm6aW"
      },
      "source": [
        "A = np.arange(24).reshape(2,3,4)\n",
        "B = A.copy()  # Realiza uma cópia de A para alocação em um novo espaço em memória para B\n",
        "print(\"---> A\\n\", A)\n",
        "print(\"---> A + B\\n\", A+B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI7V9AQHuokP"
      },
      "source": [
        "**(Exercício)** Escreva uma função em Python que permita realizar a soma ou subtração de dois arrays (vetores, matrizes ou tensores), e retorne seu resultado. Escreva sua própria solução, sem utilizar a biblioteca numpy ou similares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDMNMUZFveoD"
      },
      "source": [
        "Operações do tipo *Elementwise multiplication* entre duas matrizes são chamadas [Hadamard product](https://en.wikipedia.org/wiki/Hadamard_product_(matrices)) (notação matemática $\\odot$).\n",
        "Considere as matrizes $\\mathbf{A}$, $\\mathbf{B} \\in \\mathbb{R}^{m \\times n}$, onde cada elemento da linha $i$ e coluna $j$ é representado como $a_{ij}$, $b_{ij}$. O Hadamard product entre as matrizes $\\mathbf{A}$ e $\\mathbf{B}$ pode ser realizado da seguinte forma:\n",
        "\n",
        "$$\n",
        "\\mathbf{A} \\odot \\mathbf{B} =\n",
        "\\begin{bmatrix}\n",
        "    a_{11}  b_{11} & a_{12}  b_{12} & \\dots  & a_{1n}  b_{1n} \\\\\n",
        "    a_{21}  b_{21} & a_{22}  b_{22} & \\dots  & a_{2n}  b_{2n} \\\\\n",
        "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    a_{m1}  b_{m1} & a_{m2}  b_{m2} & \\dots  & a_{mn}  b_{mn}\n",
        "\\end{bmatrix}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0Vc3aX91j-X"
      },
      "source": [
        "#exemplo do produto entre arrays\n",
        "print(A*B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiHMsW-m1vCA"
      },
      "source": [
        "Multiplicar ou adicionar tensores por escalares não mudam a dimensão do tensor. \n",
        "Cada elemento do tensor será apenas multiplicado ou somado com o escalar. \n",
        "Veja o exmplo abaixo: "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2UCMKEE2Mn-"
      },
      "source": [
        "C = A + 2\n",
        "D = A * 2\n",
        "print('Shape A', A.shape)\n",
        "print(C)\n",
        "print(\"----------\")\n",
        "print('Shape C', C.shape)\n",
        "print(D)\n",
        "print(\"----------\")\n",
        "print('Shape D', D.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1SlqR106uwx"
      },
      "source": [
        "## Reduction\n",
        "\n",
        "Uma operação básica e bastente útil para o *machine learning* é a possibilidade e somar todos os elementos de um tensor.\n",
        "Na notação matemática, expressamos a soma utilizando o símbolo $\\sum$. \n",
        "Desta forma, para expressar a soma dos elementos de um vetor $\\mathbf{x}$ de tamanho $d$, escrevemos $\\sum_{i=1}^d x_i$. Em Python, utilizando o nunmpy, basta chamar uma função `sum`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98xWjk2kF_cu",
        "outputId": "0f30b26a-3aae-482a-db57-80cf52b2738b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#somando de todos os elementos de um vetor\n",
        "x = np.arange(4)\n",
        "print(x, x.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3] 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeUfRnzcGUz4"
      },
      "source": [
        "Pode-se expressar a soma os elementos de um tensor em qualquer dimensão. Por exemplo, a soma dos elementos de uma matriz $\\mathbf{A}$ de dimensão $m \\times n$ pode ser escrita como $\\sum_{i=1}^{m} \\sum_{j=1}^{n} a_{ij}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbEwP3FeGqAB",
        "outputId": "c28d1baa-142f-465e-c6b7-3d9d8108e2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#soma de todos os elementos de um tensor\n",
        "A = np.arange(12).reshape(6,2)\n",
        "print(A)\n",
        "print(\"Shape:\",A.shape, \"Soma: \",A.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  1]\n",
            " [ 2  3]\n",
            " [ 4  5]\n",
            " [ 6  7]\n",
            " [ 8  9]\n",
            " [10 11]]\n",
            "Shape: (6, 2) Soma:  66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2jKqvbkI4B3"
      },
      "source": [
        "Outro possibilidade de redução, pode ser a soma apenas dos elemenos de um referido axis, por exemplo, somar as linhas ou mesmo, as colunas. Veja o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ-qboviNQHM",
        "outputId": "18dbf333-b635-48cd-b1aa-3dd43bb54b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#axis 0, linhas\n",
        "A_sum_axis0 = A.sum(axis=0)\n",
        "print(A_sum_axis0, A_sum_axis0.shape)\n",
        "\n",
        "#axis 1, colunas\n",
        "A_sum_axis1 = A.sum(axis=1)\n",
        "print(A_sum_axis1, A_sum_axis1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[30 36] (2,)\n",
            "[ 1  5  9 13 17 21] (6,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwbQrq--P2qU"
      },
      "source": [
        "Pode-se calcular a média do tensor, dividindo sua soma pelo número de elementos ou apenas chamando a função `mean`. Lembre-se que também é possível informar o axis que se deseja calcular, por exemplo:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNTLF-o5P3kJ",
        "outputId": "7a661926-f0ae-40c3-9d90-520ffcbcb0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# calculando a media para todo o tensor\n",
        "print('Media: ', A.mean(), 'ou', A.sum() / A.size)\n",
        "\n",
        "#calculando a media para um referido axis\n",
        "print (A.mean(axis=0), A.sum(axis=0) / A.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Media:  5.5 ou 5.5\n",
            "[5. 6.] [5. 6.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIyA2qF2TmxK"
      },
      "source": [
        "## Produto Escalar (*Dot Products*)\n",
        "\n",
        "Umas das operações mais fundamentais da Algebra Linear é o produto escalar entre vetores.\n",
        "Dado dois vetores $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d$, seu produto escalar $\\mathbf{x}^\\top \\mathbf{y}$ (or $\\langle \\mathbf{x}, \\mathbf{y}  \\rangle$) é a soma dos produtos dos elementos na mesma posição, e isto retorna um escalar: $\\mathbf{x}^\\top \\mathbf{y} = \\sum_{i=1}^{d} x_i y_i$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPTyl9huTl01",
        "outputId": "aad09041-3989-4b3b-f7ff-43340345524f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "#dot product\n",
        "x = np.arange(4)\n",
        "y = x+1\n",
        "print('x =',x,'\\ny =',y)\n",
        "print('x.y =', np.dot(x, y))\n",
        "\n",
        "#equivalente a soma da multiplicação dos elemetos\n",
        "print('Soma da Mult: ',np.sum(x * y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x = [0 1 2 3] \n",
            "y = [1 2 3 4]\n",
            "x.y = 20\n",
            "Soma da Mult:  20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1Rc-vUr0IGC"
      },
      "source": [
        "Em *machine learning* o produto escalar entre vetores, no contexto em que dados um vetor de entrada $\\mathbf{x} \\in \\mathbb{R}^d$ e uma lista de pesos (*weights*) $\\mathbf{w} \\in \\mathbb{R}^d$, temos o seguinte produto escalar, $\\mathbf{x}^\\top \\mathbf{w}$. Considerando que os pesos são não negativos, teremos: $\\left(\\sum_{i=1}^{d} {w_i} = 1\\right)$,\n",
        "\n",
        "Lembre-se que o produto escalar entre dois vetores $\\mathbf{x}$ e $\\mathbf{y}$, pode ser expresso como o produto do comprimento (norma ou módulo) de $\\mathbf{y}$ pela projeção escalar de $\\mathbf{x}$ em $\\mathbf{y}$, temos: \n",
        "\n",
        "$\\mathbf{x}$ $\\mathbf{y}$ = |$\\mathbf{x}| |\\mathbf{y}| cos(\\theta)$ \n",
        "\n",
        "Veja:\n",
        "- [Wiki Produto Escalar](https://pt.wikipedia.org/wiki/Produto_escalar)\n",
        "- [Video Demostração](https://youtu.be/0iNrGpwZwog)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sSA5J1OIDX-",
        "outputId": "654cd0dd-0a30-43d3-dd25-912061720a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Calculando o angulo entre os vetores\n",
        "a = np.array([2,2,-1])\n",
        "b = np.array([5,-3, 2])\n",
        "\n",
        "ct = np.dot(a,b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "theta = np.arccos(ct)\n",
        "\n",
        "print('theta=',theta, 'degrees:',np.degrees(theta))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "theta= 1.4624367813109531 degrees: 83.79145537381416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtzZuc7REynL"
      },
      "source": [
        "## Protudo entre Matrizes (*Matrix-Vector Products*)\n",
        "\n",
        "Considerando duas matrizes $\\mathbf{A} \\in \\mathbb{R}^{n \\times k}$ e $\\mathbf{B} \\in \\mathbb{R}^{k \\times m}$:\n",
        "\n",
        "$$\\mathbf{A}=\\begin{bmatrix}\n",
        " a_{11} & a_{12} & \\cdots & a_{1k} \\\\\n",
        " a_{21} & a_{22} & \\cdots & a_{2k} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        " a_{n1} & a_{n2} & \\cdots & a_{nk} \\\\\n",
        "\\end{bmatrix},\\quad\n",
        "\\mathbf{B}=\\begin{bmatrix}\n",
        " b_{11} & b_{12} & \\cdots & b_{1m} \\\\\n",
        " b_{21} & b_{22} & \\cdots & b_{2m} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        " b_{k1} & b_{k2} & \\cdots & b_{km} \\\\\n",
        "\\end{bmatrix}.$$\n",
        "\n",
        "O produto matricial estabelecido em $\\mathbf{C} = \\mathbf{A}\\mathbf{B}$, é relizado nos termos em que $\\mathbf{A}$ representa um vetor linha e $\\mathbf{B}$ representa um vetor coluna. Desta forma, temos:\n",
        "\n",
        "$$\\mathbf{A}=\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\\\\n",
        "\\mathbf{a}^\\top_{2} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{a}^\\top_n \\\\\n",
        "\\end{bmatrix},\n",
        "\\quad \\mathbf{B}=\\begin{bmatrix}\n",
        " \\mathbf{b}_{1} & \\mathbf{b}_{2} & \\cdots & \\mathbf{b}_{m} \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Então o produto entre matrizes $\\mathbf{C} \\in \\mathbb{R}^{n \\times m}$ é realizado simplemente calculando o produto escalar de cada elemento \n",
        "$c_{ij}$ =  $\\mathbf{a}^\\top_i \\mathbf{b}_j$:\n",
        "\n",
        "\n",
        "$$\\mathbf{C} = \\mathbf{AB} = \\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\\\\n",
        "\\mathbf{a}^\\top_{2} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{a}^\\top_n \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        " \\mathbf{b}_{1} & \\mathbf{b}_{2} & \\cdots & \\mathbf{b}_{m} \\\\\n",
        "\\end{bmatrix}\n",
        "= \\begin{bmatrix}\n",
        "\\mathbf{a}^\\top_{1} \\mathbf{b}_1 & \\mathbf{a}^\\top_{1}\\mathbf{b}_2& \\cdots & \\mathbf{a}^\\top_{1} \\mathbf{b}_m \\\\\n",
        " \\mathbf{a}^\\top_{2}\\mathbf{b}_1 & \\mathbf{a}^\\top_{2} \\mathbf{b}_2 & \\cdots & \\mathbf{a}^\\top_{2} \\mathbf{b}_m \\\\\n",
        " \\vdots & \\vdots & \\ddots &\\vdots\\\\\n",
        "\\mathbf{a}^\\top_{n} \\mathbf{b}_1 & \\mathbf{a}^\\top_{n}\\mathbf{b}_2& \\cdots& \\mathbf{a}^\\top_{n} \\mathbf{b}_m\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "O produto entre vetores ou matrizes obedece basicamente as mesmas regras e podem ser realizados utilizando a função `dot`. \n",
        "Importante, não confundir o produto entre matrizes com *Hadamard product*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B54bEBb9H6c-"
      },
      "source": [
        "# Produto entre matrizes\n",
        "A = A = np.arange(6).reshape(3,2)\n",
        "B = np.ones(shape=(3, 2))\n",
        "C = np.dot(A.T, B)\n",
        "\n",
        "print(\"A:\\n\", A.T)\n",
        "print(\"B:\\n\", B)\n",
        "print(\"C:\\n\", C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09X5ghqXJ5z6"
      },
      "source": [
        "## Norma (módulo)\n",
        "\n",
        "Um dos operadores mais mais úteis na álgebra linear é a norma ou módulo, que representa o comprimento de um vetor. A norma não se refere-se à dimensionalidade, mas à magnitude dos componentes.\n",
        "\n",
        "Você deve notar que a norma pode ser vista como a medição de uma distância.\n",
        "Lembre-se que na distância euclidiana, do teorema de Pitágoras estudada no ensino médio, propriedades da norma como a obtenção de valores não negativos e a desigualdade de triângulos já foram apresentados.\n",
        "Segue algumas propriedades:\n",
        "\n",
        "multiplicação por uma constante,\n",
        "$$f(\\alpha \\mathbf{x}) = |\\alpha| f(\\mathbf{x}).$$\n",
        "\n",
        "inegualdade triangular,\n",
        "$$f(\\mathbf{x} + \\mathbf{y}) \\leq f(\\mathbf{x}) + f(\\mathbf{y}).$$\n",
        "\n",
        "a norma éé um valor não negativo:\n",
        "$$f(\\mathbf{x}) \\geq 0.$$\n",
        "\n",
        "Continuando, temos a distância Euclidiana dada pela seguinte norma $\\ell_2$.\n",
        "Suponha que os elementos de um vetor $n$-dimensional $\\mathbf{x}$ são $x_1, \\ldots, x_n$. A norma $\\ell_2$ de $\\mathbf{x}$ é a raiz quadrada da soma dos quadrados dos elementos de um vetor:\n",
        "\n",
        "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2},$$\n",
        "\n",
        "onde o *subscript* $2$ é normalmente omitido em normas do tipo $\\ell_2$ norms, por exemplo, $\\|\\mathbf{x}\\|$ is equivalent to $\\|\\mathbf{x}\\|_2$. Codificando isso, pode-se calcular a norma $\\ell_2$ de um vetor utilizando `linalg.norm`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9XOIbJ7eKkI",
        "outputId": "4279bcbe-f67d-40bd-d772-84f2aeadcee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#calculando a norma\n",
        "u = np.array([3, -4])\n",
        "print(np.linalg.norm(u))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmhHPzmeR00a"
      },
      "source": [
        "Veremos que é bem comum em *deep learning*, trabalhar com normas do tipo  $\\ell_2$, menos influenciável por outliers. Em alguns casos é necessário a utilização da norma $\\ell_1$, expressa pela soma dos valores absolutos dos elementos do vetor:\n",
        "\n",
        "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|.$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu8chfjAU2RT",
        "outputId": "385730d0-d882-4232-e0cb-1087d066477d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Norma l1\n",
        "np.abs(u).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}